<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>reveal.js</title>

		<link rel="stylesheet" href="dist/reset.css">
		<link rel="stylesheet" href="dist/reveal.css">
		<link rel="stylesheet" href="dist/theme/solarized.css" id="theme">

		<!-- Theme used for syntax highlighted code -->
		<link rel="stylesheet" href="plugin/highlight/monokai.css" id="highlight-theme">
		<style type="text/css">
			p {
				font-family: Avenir, serif;
			}
		</style>
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
				<section data-background-color="#093028">
					<p style="font-family: Avenir,serif; font-size: 35px;" class="text-color-white">Excalibur: effici√´nt en interactief zoeken in grote hoeveelheden afbeeldingen </p>
					<p style="font-family: Avenir,serif; font-size: 30px; margin-top: 50px;">Digitober</p>
					<p style="font-family: Avenir,serif; font-size: 20px;">Mark Berger, Ronald van Velzen, Robin Bakker, Niels Dekker</p>
					<p style="font-family: Avenir,serif; font-size: 20px;">12-09-2022</p>
					<aside class="notes">
						Welkom iedereen bij de Digitober presentatie over Excalibur! Mijn naam is Mark Berger, en dit is mijn collega Ronald van Velzen.
						Vandaag willen we jullie meenemen in de wondere wereld van zoeksystemen, met name zoeken in afbeeldingen. Wat gaan we vandaag doen?
					</aside>
				</section>
				<section data-background-color="#093028">
					<p style="font-family: Avenir, serif; font-size: 55px;" class="text-color-white">Agenda van de dag</p>
					<ul>
						<li style="font-size: 25px; font-family: Avenir, serif;" class="text-color-2">
							Introductie sprekers & CoDE üë®‚Äçüíª
						</li>
						<li style="font-size: 25px; font-family: Avenir, serif;" class="text-color-2">
							Waarom zoeken in afbeeldingen? üîç
						</li>
						<li style="font-size: 25px; font-family: Avenir, serif;" class="text-color-2">
							Excalibur üó°Ô∏è
							<ul>
								<li style="font-size: 20px; font-family: Avenir, serif;" class="text-color-2">
									Hoe werkt zoeken eigenlijk? üßê
								</li>
								<li style="font-size: 20px; font-family: Avenir, serif;" class="text-color-2">
									Wat zit er onder de kap bij Excalibur? ü§ì
								</li>
								<li style="font-size: 20px; font-family: Avenir, serif;" class="text-color-2">
									Demo! ü§©
								</li>
							</ul>
						</li>
						<li style="font-size: 25px; font-family: Avenir, serif;" class="text-color-2">
							Volgende stappen ü¶ø
						</li>
						<li style="font-size: 25px; font-family: Avenir, serif;" class="text-color-2">
							Tijd voor vragen ‚ùì
						</li>
						<li style="font-size: 25px; font-family: Avenir, serif;" class="text-color-2">
							Zelf aan de gang met Excalibur! üë©‚Äçüî¨
						</li>
					</ul>
				</section>
				<section data-background-color="#093028">
					<section data-background-color="#093028">
						<h4 style="position: relative; font-family: Avenir, serif; color: whitesmoke">Wie zijn wij?</h4>
					</section>
					<!-- Mark -->
					<section data-background-color="#093028">
						<p style="font-family: Avenir, serif; color: whitesmoke">Mark Berger</p>
						<div>
							<img style="width: 300px; clip-path: circle(); float: left; position: relative; right: 90px" src="assets/mark.jpg"/>
							<ul style="bottom: 380px; left: 100px; float: right; position: relative;">
								<li style="font-size: 25px; font-family: Avenir, serif; margin: 10px;" class="text-color-2">
									Bachelor Kunstmatige Intelligentie @ Universiteit Utrecht
								</li>
								<li style="font-size: 25px; font-family: Avenir, serif; margin: 10px" class="text-color-2">
									Master Information Systems @ Universiteit van Amsterdam
								</li>
								<li style="font-size: 25px; font-family: Avenir, serif; margin: 10px" class="text-color-2">
									Sinds 2018 bij de FIOD als Data Scientist / ML engineer
								</li>
								<li style="font-size: 25px; font-family: Avenir, serif; margin: 10px" class="text-color-2">
									Eerst project DGO, en nu CoDE
								</li>
								<li style="font-size: 25px; font-family: Avenir, serif; margin: 10px" class="text-color-2">
									Geinteresseerd in slim zoeken, generatieve AI, en interactieve systemen
								</li>
								<!-- TODO: misschien wat leuke gegenereerde afbeeldingen hier ;) -->
							</ul>
						</div>
						<aside class="notes">
							Ik ben Mark, ik werk al sinds 2018 bij de FIOD, als een van de eerste developers van het DGO platform, wat nu uitgegroeid
							is naar CoDE.
						</aside>
					</section>
					<!-- Ronald -->
					<section data-background-color="#093028">
						<p style="font-family: Avenir, serif;" class="text-color-white">Ronald van Velzen</p>
						<aside class="notes">
							Ik ben Ronald...
						</aside>
					</section>
					<!-- CoDE -->
					<section data-background-color="#c9d4d6">
						<!-- <p style="font-family: Avenir, serif; font-size: 50px;" class="text-color-white">CoDE</p> -->
						<img src="assets/CoDE logo.svg" style="width: 30%;"/>
						<blockquote style="font-family: Avenir, serif; font-size: 35px; text-align: left; color: black; border-color: black; padding-left: 20px;">
							CoDE staat voor <p style="display: inline" class="fragment highlight-blue" data-fragment-index="1">C</p>enter <p style="display: inline" class="fragment highlight-blue" data-fragment-index="1">o</p>f <p
							style="display: inline" class="fragment highlight-blue" data-fragment-index="1">D</p>ata <p
							style="display: inline" class="fragment highlight-blue" data-fragment-index="1">E</p>xpertise.
							We ontwikkelen applicaties die het werk van de rechercheur <p style="display: inline" class="fragment highlight-blue" data-fragment-index="2">makkelijker</p> moeten maken. 
							<br><br>
							Onze doelstellingen zijn daarbij: gebruik <p style="display: inline" class="fragment highlight-blue" data-fragment-index="3">nieuwe algoritmes en technologieen</p> 
							om <p style="display: inline" class="fragment highlight-blue" data-fragment-index="4">data te reduceren</p>, <p style="display: inline" class="fragment highlight-blue" data-fragment-index="4">te verrijken</p>, en om te zetten naar een <p style="display: inline" class="fragment highlight-blue" data-fragment-index="4">handig formaat</p>.
						</blockquote>
						<!-- <p style="font-family: Avenir, serif;" class="text-color-white">Center of Data Expertise</p> -->
						<aside class="notes">
							CoDE staat voor Center of Data Expertise. We ontwikkelen applicaties die het werk van de 
							rechercheur moet vergemakkelijken. Onze doelstellingen zijn daarbij: gebruik nieuwe algoritmes en technologieen
							om data te reduceren, te verrijken en om te zetten naar een handig formaat.
						</aside>
					</section>
				</section>
				<section data-background-color="#093028">
					<section data-background-color="#093028">
						<h4 style="position: relative; font-family: Avenir, serif; color: whitesmoke;">Zoeken in afbeeldingen</h4>
						<aside class="notes">
							Nu dat jullie weten wie we zijn willen we graag aftrappen met de vraag: Waarom willen we eigenlijk zoeken in afbeeldingen?
						</aside>
					</section>
					<section data-background-color="#093028" data-auto-animate>
						<p style="font-family: Avenir, serif;" class="text-color-white">Ongestructureerde data domineert</p>
						<div>
							<img src="assets/iphone-14-pro-concept-pil.png" style="width: 50%; float: left;"/>
							<img src="assets/car.jpeg" style="width: 7%;
							position: relative;
							right: 405px;
							top: 100px;"/>
							<img src="assets/chat_app.jpeg" style="width: 4%;
							position: relative;
							right: 500px;
							top: 120px;"/>
							<img src="assets/audio.jpeg" style="width: 7%;
							position: relative;
							right: 550px;
							top: 50px;"/>
						</div>
						<aside class="notes">
							phone
						</aside>
					</section>
					<section data-background-color="#093028" data-auto-animate>
						<p style="font-family: Avenir, serif;" class="text-color-white">Ongestructureerde data domineert</p>
						<div>
							<img src="assets/iphone-14-pro-concept-pil.png" style="width: 50%; float: left; position: relative; top: 50px;"/>
							<!-- <p style="float: left;
							padding: 30px;" class="text-color-2">Images</p> -->
							<!-- <img src="assets/Arrow_east.png" style="position: absolute;
							width: 20%;
							right: 50%;
							bottom: 60%;
							transform: rotate(-30deg);" class="fragment fade-in" data-fragment-index="1"/> -->
							<img src="assets/car.jpeg" style="width: 25%; display: block;"/>
							<!-- <img src="assets/Arrow_east.png" style="position: absolute;
							width: 20%;
							right: 50%;
							bottom: 42%;
							transform: rotate(25deg);" class="fragment fade-in" data-fragment-index="1"/> -->
							<!-- <p style="float: left;
							padding: 30px;" class="text-color-2">Text</p> -->
							<img src="assets/chat_app.jpeg" style="width: 10%; display: block;"/>
							<!-- <img src="assets/Arrow_east.png" style="position: absolute;
							width: 20%;
							right: 52%;
							bottom: 32%;
							transform: rotate(45deg);" class="fragment fade-in" data-fragment-index="1"/> -->
							<img src="assets/audio.jpeg" style="width: 25%; position: relative; left: 12.5%; bottom: 20px;"/>
						</div>
						<aside class="notes">
							Plaatjes, text in de vorm van chat berichten en textuele documenten, en ook audio (en video).
							VRAAG AAN PUBLIEK: Hoeveel plaatjes staan er normaal gesproken op een inbeslaggenomen apparaat?
						</aside>
					</section>
					<section data-background-color="#093028">
						<!-- <h4 style="position: relative; font-family: Avenir, serif; color: whitesmoke;">Mobiele telefoons</h4> -->
						<h4 class="r-fit-text" style="color: rgb(181, 234, 230);">1.72 triljoen per jaar</h4>
						<h4 class="r-fit-text fragment fade-in" style="color: rgb(181, 234, 230);">4.7 miljard per dag</h4>
						<h4 class="r-fit-text fragment fade-in" style="color: rgb(181, 234, 230);">6.9 miljard verstuurd per dag</h4>
						<aside class="notes">
							Er worden 1.7 triljoen foto's per jaar genomen in de laatste jaren, ofwel 4.7 miljard per dag.
							Gemiddeld worden er bijna 7 miljard afbeeldingen per dag verstuurd over WhatsApp alleen. 
						</aside>
					</section>
					<section data-background-color="#093028">
						<p style="font-family: Avenir, serif;" class="text-color-white">Opslag</p>
						<p style="display: inline; font-size: 25px;" class="text-color-2">Een gemiddeld telefoon kan anno 2022 rond de</p> <p style="display: inline; font-size: 25px;" class="fragment highlight-green text-color-2" data-fragment-index="1">35.500 foto's</p> 
						<p style="display: inline; font-size: 25px;" class="text-color-2">opslaan.</p>
					<p style="display: inline; font-size: 25px;" class="text-color-2">Volgens een onderzoek, hebben mensen in 2022 gemiddeld</p> <p style="display: inline; font-size: 25px;" class="fragment highlight-green text-color-2" data-fragment-index="1">2.400 foto's</p> 
					<p style="display: inline; font-size: 25px;" class="text-color-2">op hun iPhone staan.<sup>*</sup></p> 
					<br><br>
					<div class="fragment fade-in" data-fragment-index="1">
						<p style="display: inline; font-size: 25px;" class="text-color-2">Echter zijn deze getallen misleidend: de forensische images van de telefoons die wij afnemen hebben veel meer afbeeldingen.
						Dit komt door allerlei systeem afbeeldingen en icoontjes die op zo'n device kunnen schuilen. Ervaring vertelt dat we het makkelijk over</p> 
						<p style="display: inline; font-size: 25px;" class="fragment highlight-green text-color-2" data-fragment-index="2">50.000+ afbeeldingen</p>
						<p style="display: inline; font-size: 25px;"> <p style="display: inline; font-size: 25px;" class="text-color-2"> per device kunnen praten...</p>
						<img src="assets/icons.jpeg" style="width: 30%; float: right">
					</div>
					<p style="font-size: 15px; float: left; position: relative; top: 70px;"><sup>*</sup> https://photutorial.com/photos-statistics/</p>
						<aside class="notes">
							Een gemiddeld telefoon kan anno 2022 rond de 35.500 foto's opslaan. Volgens een onderzoek, hebben mensen in 2022 gemiddeld 2.400 foto's op hun iPhone staan.
							Echter zijn deze getallen misleidend: de forensische images van de telefoons die wij afnemen hebben veel meer afbeeldingen. 
							Dit komt door allerlei systeem afbeeldingen en icoontjes die op zo'n device kunnen schuilen. 
							Ervaring vertelt dat we het makkelijk over 50.000+ afbeeldingen per device kunnen praten...
						</aside>
					</section>
					<section data-background-color="#093028">
						<blockquote style="font-family: Avenir, serif; font-size: 35px; text-align: left; color: whitesmoke; border-color: black; padding-left: 20px;">
							<p style="display: inline" class="fragment highlight-green" data-fragment-index="1">Data reductie</p> is essentieel. 
							Wij willen een systeem hebben die <p style="display: inline" class="fragment highlight-red" data-fragment-index="2">100.000</p> te bekijken afbeeldingen reduceert tot
							<p style="display: inline" class="fragment highlight-green" data-fragment-index="3">100</p> te bekijken afbeeldingen.
							<br><br>
							<p style="display: inline" class="fragment highlight-green" data-fragment-index="4">Zo komt een rechercheur of analyst snel toe aan de data die er toe doet.</p>
						</blockquote>
						<aside class="notes">
							Data reductie is essentieel. Wij willen een systeem hebben die 100.000 te bekijken afbeeldingen reduceert tot 100 te bekijken afbeeldingen.
							Zo komt een rechercheur of analyst snel toe aan de data die er toe doet.
						</aside>
					</section>
				</section>
				<section data-background-color="#093028">
					<section>
						<h2 style="color: whitesmoke;">Excalibur</h2>
						<aside class="notes">
							Nu dat de noodzaak om het aantal afbeeldingen te reduceren duidelijk is, hoe krijgen we dit voor elkaar?
							Dat is precies waar Excalibur van pas komt.
						</aside>
					</section>
					<section>
						<p style="color: whitesmoke;">Excalibur is een zoeksysteem</p>
						<iframe data-src="https://en.wikipedia.org/wiki/Search_engine" style="width: 100%; height: 530px;"></iframe>
						<aside class="notes">
							Excalibur is een speciaal soort systeem. Namelijk een zoeksysteem. Laten we beginnen met de definitie van een zoeksysteem op Wikipedia.
							Een zoeksysteem is een software systeem wat gemaakt is om het World Wide Web te doorzoeken. Velen zullen bij een zoeksysteem aan Google denken, 
							maar het is maar 1 voorbeeld van een zoeksysteem. Systemen verschillen in omvang van de doorzoekbare data, het zoekmodaliteit (text, plaatjes, audio),
							toegang (openbaar en prive), en domein. 
							
							Hier rechts zien we voorbeelden van zoeksystemen. 
							Dit zijn voornamelijk systemen die werken zoals meesten van jullie waarschijnlijk gewend zijn, namelijk vergelijkbaar met Google.
							Je typt wat in, en je krijgt een reeks websites die relevant zijn. Maar de resultaten kunnen ook anders zijn.
						</aside>
					</section>
					<section>
						<p style="color: whitesmoke;">WolframAlpha</p>
						<iframe data-src="https://www.wolframalpha.com/" style="width: 100%; height: 530px;"></iframe>
						<aside class="notes">
							Zoals bijvoorbeeld Wolfram Alpha. Dit is een speciaal zoeksysteem wat voor academia is ontwikkeld, maar ook gebruikt kan worden
							voor het zoeken van informatie over verschillende sociaal-wetenschappelijke themas.
							Zoals je hier kan zien zijn er veel topics waarbinnen je kan zoeken. Laten we zeggen dat we geinteresseerd zijn in de Franse revolutie.
							Het systeem begrijpt mijn aanvraag, en geeft gestructureerde informatie terug over het event. Dit soort resultaten zijn ook wel een voorbeeld 
							van iets wat semantic web heet, maar daar ga ik nu niet verder op in.
						</aside>
					</section>
					<section>
						<p style="color: whitesmoke;">Text doorzoeken</p>
						<p style="font-size: 25px; float: left; padding: 7px;" class="text-color-2 r-frame"> üîç Geparkeerde blauwe auto</p>
						<table class="tg fragment fade-in" data-fragment-index="1" style="width: 600px; font-size: 20px; color: whitesmoke; display: block;
						position: relative;
						right: 39%; top: 100px;">
							<thead>
							  <tr>
								<th class="tg-1wig">Zoekresultaat</th>
								<th class="tg-1wig">Overeenkomst</th>
							  </tr>
							</thead>
							<tbody>
							  <tr>
								<td class="tg-0lax">"Blauwe auto"</td>
								<td class="tg-0lax">93%</td>
							  </tr>
							  <tr>
								<td class="tg-0lax">"Geparkeerde auto"</td>
								<td class="tg-0lax">90%</td>
							  </tr>
							  <tr>
								<td class="tg-0lax">"Auto in de straat"</td>
								<td class="tg-0lax">79%</td>
							  </tr>
							  <tr>
								<td class="tg-0lax">"Parkeergarage met auto's"</td>
								<td class="tg-0lax">79%</td>
							  </tr>
							</tbody>
						</table>
						<img src="assets/rightside.png" style="width: 55%; -webkit-filter: invert(100%);
						filter: invert(100%); position: relative; bottom: 170px; left: 20%;" class="fragment fade-in" data-fragment-index="2">
						<p style="color: whitesmoke; position: absolute;
						font-size: 25px;
						top: 450px;
						left: 590px;" class="fragment fade-in" data-fragment-index="3">"bag-of-words"</p>
						<p style="color: whitesmoke; position: absolute;
						font-size: 25px;
						top: 450px;
						left: 850px;" class="fragment fade-in" data-fragment-index="4">"vector"</p>
						<img src="assets/arrow_rightside.png" style="width: 68%; -webkit-filter: invert(100%);
						filter: invert(100%); position: relative; bottom: 265px; left: 10%;" class="fragment fade-in" data-fragment-index="5">
						<aside class="notes">
							Een vrij simpele techniek voor het doorzoeken van tekst werkt als volgt: we transformeren onze data op basis van "bag-of-words" --> alle zinnen worden verzamelingen aan woorden, zonder structuur. 
							Vervolgens kunnen we de voorkomens van elk woord uit onze input zin tellen in alle andere zinnen. Deze voorkomens vormen samen een numerieke representatie van een zin, de zogenaamde vector.
							Fijne aan deze vectoren is dat er mee gerekend kan worden! Zo kunnen we bijvoorbeeld afstanden tussen de vectoren berekenen, en op basis daarvan de overeenkomsten. Voor een computer is menselijk taal
							begrijpen een hele lastige taak, maar door taal om te zetten naar getallen, kan de computer er wat mee!
						</aside>
					</section>
					<section data-background-color="#d6c9d9">
						<p style="color: black;">Text doorzoeken: advanced</p>
						<p style="color: black; font-size: 30px; padding-top: 70px; ">"Deze blauwe auto staat geparkeerd"</p>
						<!-- <img src="assets/nn.png" style="width: 70%;"> -->
						<!-- <p style="color: black; font-size: 20px;
						position: absolute;
						top: 215px;">Geparkeerde</p>
						<p style="color: black; font-size: 20px;">blauwe</p>
						<p style="color: black; font-size: 20px;">auto</p>
						<p style="color: black; font-size: 20px;">staat</p>
						<p style="color: black; font-size: 20px;">daar</p> -->
						<!-- <iframe style="width: 100%; max-width: 100% !important; height: 530px;"src="https://playground.tensorflow.org/#activation=relu&regularization=L2&batchSize=10&dataset=gauss&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=10&networkShape=4&seed=0.81866&showTestData=false&discretize=false&percTrainData=80&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false"></iframe> -->
						<aside class="notes">
							Echter, deze bag-of-words manier van representaties maken is vaak te simpel om complexe betekenis van tekst vast te leggen. Een veel krachtigere manier om text representaties te creeren is door gebruik
							te maken van neurale netwerken. Dit zijn speciale machine learning modellen die complexe patronen en eigenschappen kunnen leren van de input data. De output van zo'n model kan een classificatie zijn, 
							maar ook een vector zoals die getoond is op de vorige slide. Alleen zijn de vectoren die een neuraal netwerk produceert een heel stuk groter: je kan denken aan vectoren van bijvoorbeeld 512 getallen lang.
						</aside>
					</section>
					<section data-background-color="#d6c9d9">
						<p style="color: black;">Neuraal netwerk</p>
						<!-- <p style="color: black; font-size: 25px;">Geparkeerde blauwe auto staat daar</p> -->
						<img src="assets/nn.png" style="width: 70%;">
						<p style="color: black; font-size: 20px;
						position: absolute;
						top: 215px; left: 10%;">Deze ‚ûú</p>
						<p style="color: black; font-size: 20px;
						position: absolute;
						top: 285px; left: 8%;">blauwe ‚ûú</p>
						<p style="color: black; font-size: 20px;
						position: absolute;
						top: 355px; left: 10.4%;">auto ‚ûú</p>
						<p style="color: black; font-size: 20px;
						position: absolute;
						top: 425px; left: 10%;">staat ‚ûú</p>
						<p style="color: black; font-size: 20px;
						position: absolute;
						top: 495px; left: 3.6%;">geparkeerd ‚ûú</p>
						<p style="color: black; font-size: 20px;
						position: absolute;
						left: 34.2%;
    					top: 35.2%;" class="fragment fade-in" data-fragment-index="1">0.78</p>
						<p style="color: black; font-size: 20px;
						position: absolute;
						left: 34.2%;
    					top: 46.6%;" class="fragment fade-in" data-fragment-index="2">0.06</p>
						<p style="color: black; font-size: 20px;
						position: absolute;
						left: 33.8%;
    					top: 58.1%;" class="fragment fade-in" data-fragment-index="3">-0.98</p>
						<p style="color: black; font-size: 20px;
						position: absolute;
						left: 34.2%;
    					top: 69.5%;" class="fragment fade-in" data-fragment-index="3">0.46</p>
						<p style="color: black; font-size: 20px;
						position: absolute;
						left: 34.2%;
    					top: 80.6%;" class="fragment fade-in" data-fragment-index="3">0.12</p>
						<p style="color: black; font-size: 20px;
						position: absolute;
						left: 48.1%;
    					top: 80.6%;" class="fragment fade-in" data-fragment-index="3">-0.04</p>
						<p style="color: black; font-size: 20px;
						position: absolute;
						left: 48.6%;
    					top: 69.5%" class="fragment fade-in" data-fragment-index="3">0.24</p>
						<p style="color: black; font-size: 20px;
						position: absolute;
						left: 48.6%;
    					top: 58.1%;" class="fragment fade-in" data-fragment-index="3">0.57</p>
						<p style="color: black; font-size: 20px;
						position: absolute;
						left: 48.1%;
    					top: 35.2%;" class="fragment fade-in" data-fragment-index="3">-0.13</p>
						<p style="color: black; font-size: 20px;
						position: absolute;
						left: 62.8%;
    					top: 46.6%;" class="fragment fade-in" data-fragment-index="3">0.42</p>
						<p style="color: black; font-size: 20px;
						position: absolute;
						left: 62.8%;
    					top: 58.1%;" class="fragment fade-in" data-fragment-index="3">0.37</p>
						<p style="color: black; font-size: 20px;
						position: absolute;
						left: 62.8%;
    					top: 35.2%;" class="fragment fade-in" data-fragment-index="3">0.10</p>
						<p style="color: black; font-size: 20px;
						position: absolute;
						left: 62.4%;
    					top: 69.5%;" class="fragment fade-in" data-fragment-index="3">-0.69</p>
						<p style="color: black; font-size: 20px;
						position: absolute;
						left: 62.4%;
    					top: 80.6%;" class="fragment fade-in" data-fragment-index="3">-0.22</p>
						<p style="color: black; font-size: 20px;
						position: absolute;
						left: 48.6%;
    					top: 46.6%;" class="fragment fade-in" data-fragment-index="3">0.86</p>
						<p style="color: black; font-size: 25px;
						position: absolute;
						left: 77.7%;
						top: 46.2%;" class="fragment fade-in">üöô</p>
						<p style="color: black; font-size: 25px;
						position: absolute;
						left: 77.7%;
						top: 57.2%;" class="fragment fade-in">üöó</p>
						<p style="color: black; font-size: 25px;
						position: absolute;
						left: 77.7%;
						top: 68.2%;" class="fragment fade-in">üèéÔ∏è</p>
						<p style="color: black; font-size: 25px;
						position: absolute;
						left: 83.7%;
						top: 46.2%;" class="fragment fade-in">‚úÖ</p>
						<!-- <iframe style="width: 100%; max-width: 100% !important; height: 530px;"src="https://playground.tensorflow.org/#activation=relu&regularization=L2&batchSize=10&dataset=gauss&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=10&networkShape=4&seed=0.81866&showTestData=false&discretize=false&percTrainData=80&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false"></iframe> -->
						<aside class="notes">
							De zin "Deze blauwe auto staat geparkeerd" halen we woord voor woord door ons neuraal netwerk algoritme. 
							Dat zien we hier links. Elk woord gaat er los in. Vervolgens worden er heel veel wiskundige operaties uitgevoerd
							in deze drie lagen, waarbij elk rondje hier voor een zogenaamd neuroon staat, wat steeds in waarde veranderd
							gedurende het trainingsproces. Aan het eind van het model trainingsproces heeft elk neuroon een waarde gekregen.
							Vervolgens kunnen we de waardes op zo'n manier aggregeren dat we een voorspelling kunnen doen over in wat voor onderwerp
							dit specifiek zinnetje valt. In ons geval willen we dat het neuraal netwerk het onderwerp "blauwe auto's" voorspelt.
						</aside>
					</section>
					<section data-background-color="rgb(247, 247, 247)">
						<p style="color: black;">Neuraal netwerk in actie</p>
						<iframe style="position: relative; right:140px; width: 1200px; max-width: 1200px; height: 530px;"src="https://playground.tensorflow.org/#activation=relu&regularization=L2&batchSize=10&dataset=gauss&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=10&networkShape=4&seed=0.81866&showTestData=false&discretize=false&percTrainData=80&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false"></iframe>
						<aside class="notes">
							We gaan nog een stukje verder, met een live demonstratie hoe een neuraal netwerk werkt. Laten we het netwerk
							van de vorige slide hier nabouwen. Alleen gaan we uit dat we maar twee onderwerpen kunnen voorspellen, in plaats van drie.
							We zien hier links FEATURES staan. Features zijn de eigenschappen die elk iets vertellen over de data. In ons geval 
							vertelt elk woord uit onze zin iets over onze zin, dus is elk woord ook een feature. We hadden 5 woorden in onze zin,
							dus we kiezen hier ook vijf features. In ons voorbeeld van net hadden we drie neuroon lagen met steeds 5 neuron per laag. 
							Laten we het hier ook doen. Ik laat de resterende parametrisatie nu voor wat het is. 
							
							De achtergrond kleuren hier rechts geven de klasse attributie aan voor de punten. 
							Je ziet aan begin dat alles een beetje random kleur heeft: dat komt omdat het model nu nog niet weet welke punten bij elkaar horen
							en wat de klasse attributie is. Je ziet ook elke keer dat als ik de initiele distributie refresh, dat de loss hier rechtsboven veranderd.
							Loss geeft eigenlijk aan hoe ver de voorspellingen van het model af staan van de echte categorieen.

							Als we nu op Play drukken hier dan begint het algoritme te trainen. 
							Je ziet dat het model al snel de scheiding leert te maken tussen twee klasses en de loss snel afneemt.
							Dit is natuurlijk een versimplificatie van de werkelijkheid want in praktijk hebben we te maken met stuk meer features, 
							en vooral, veel meer output classes. 
						</aside>
					</section>
					<section data-background-color="#d6c9d9">
						<p style="color: black;">Vector representaties</p>
						<img src="assets/vector_indication.png" style="position: relative;
						bottom: 25px;" class="fragment fade-in">
						<aside class="notes">
							Zo, dat was even een technisch stukje algoritmiek. Hoe komt het stuk Text doorzoeken samen met hetgeen wat
							ik net liet zien? Nou, als het goed is herrineren jullie je nog de kleine bag-of-words vectoren van een paar slides geleden,
							dus [1,0,1] enzo. Deze simpele vectoren kunnen we, nu dat het modeel getraind is, vervangen door complexere en langere vectoren,
							die veel meer van de semantiek (betekenis) van de tekst vangen. De getallen van de laatste laag van ons neuraal netwerk
							kan als zo'n vector dienen!
						</aside>
					</section>
					<section data-background-color="#093028">
						<p style="color: whitesmoke;">Afbeeldingen doorzoeken met tekst</p>
						<!-- <img src="assets/vector_indication.png" style="position: relative;
						bottom: 25px;" class="fragment fade-in"> -->
						<img src="assets/car.jpeg" style="float: left; width: 40%" class="fragment fade-in" data-fragment-index="1">
						<img src="assets/Arrow_east.png" style="width: 10%;
						float: left;
						position: relative;
						-webkit-filter: invert(100%);
						filter: invert(100%);
						left: 10px;
						top: 110px;" class="fragment fade-in" data-fragment-index="2">
						<img src="assets/vector1.png" style="width: 5%; -webkit-filter: invert(100%);
						filter: invert(100%); position: relative; top: 15px; right: 8%;" class="fragment fade-in" data-fragment-index="2">
						<img src="assets/Arrow_east.png" style="width: 10%;
						float: left;
						position: relative;
						-webkit-filter: invert(100%);
						filter: invert(100%);
						left: 95px;
						top: 110px;
						rotate: 180deg;" class="fragment fade-in" data-fragment-index="2">
						<p style="color: whitesmoke; font-size: 20px;  float: right;
						position: relative;
						display: inline;
						top: 115px; left: 50px;" class="fragment fade-in" data-fragment-index="1">Groene sportauto rijdt op het circuit</p>
						<aside class="notes">
							Nu dat we een manier hebben bekeken om teksten met elkaar te vergelijken op basis van vector representaties, 
							is de volgende stap natuurlijk: hoe vergelijken we afbeeldingen met tekst (en afbeeldingen met andere afbeeldingen)?
							Wat we eigenlijk willen is een neuraal netwerk wat zowel afbeeldingen als tekst binnen een vector ruimte kan plaatsen!
						</aside>
					</section>
					<section data-background-color="white">
						<p style="color: black;">CLIP model: plaatjes en tekst bij elkaar</p>
						<img src="assets/clip_training1.svg" style="width: 80%;">
						<aside class="notes">
							Gelukkig is precies zo'n model recent uitgebracht door OpenAI, het AI bedrijf van Elon Musk. Dit model is open
							source beschikbaar en werkt grof gezegd als volgt: er is enorm veel data van het internet verzameld in de vorm
							van plaatje-text paren, zoals bijvoorbeeld een Instagram post, die bestaat uit een foto en een tekstje eronder.
							De aanname hierbij is dat de text onder een foto gerelateerd is aan de foto. Op basis van deze aanname wordt
							er een neuraal netwerk getraind wat als doel heeft om de plaatjes met de passende tekst zo dicht mogelijk bij elkaar
							te krijgen in de vector ruimte van het model. Door dit lang genoeg te doen op heel veel data leert het model
							om een stukje tekst te relateren aan een plaatje wat semantisch gezien vergelijkbare inhoud heeft, zoals bijvoorbeeld
							onze groene sportauto voorbeeld van net.
						</aside>
					</section>
					<section data-background-color="white">
						<p style="color: black;">CLIP model: afbeeldingen en tekst bij elkaar</p>
						<img src="assets/clip2.svg" style="width: 70%;">
						<aside class="notes">
							In praktijk betekent het dat als een gebruiker een tekstuele query doet, zoals "a photo of a dog",
							en er bestaat een afbeelding van een hond in de collectie van afbeeldingen, dan zal het model
							deze twee aan elkaar relateren. Dat doet het model aan de hand van de geleerde relaties (wiskundige definitie is dot-product)
							tussen de afbeelding encoding en de text encoding. Als er meerdere afbeeldingen in de dataset aanwezig zijn 
							met honden erop dan verwachten we dat die allemaal een vrij hoge score hebben ten opzichte van de textuele query, 
							en kunnen we ze dus allemaal ophalen. De sortering in de zoekresultaten komt dan overeen met de
							score tussen de tekstuele zoekvraag en het afbeelding.
						</aside>
					</section>
					<section data-background-color="#d6c9d9">
						<p style="color: black;">Maar ook afbeeldingen zoeken met afbeeldingen!</p>
						<img src="assets/reverse_search_lens.png" style="width: 90%;">
						<aside class="notes">
							Omdat het model de data in dezelfde representatie ruimte zet, kunnen we ook prima een afbeelding
							vergelijken met andere afbeeldingen. Met andere woorden, we kunnen een afbeelding gebruiken als zoekvraag om
							andere afbeeldingen door te zoeken!

							Op deze slide zien we een voorbeeld van Google het doet met hun reverse image search oplossing
							genaamd Google Lens.
						</aside>
					</section>
					<section data-background-color="#1e81b0">
						<p style="color: black;">En nu wil ik het zien werken!</p>
						<iframe style="position: relative; right:140px; width: 1200px; max-width: 1200px; height: 530px;"src="http://localhost:8080/#/"></iframe>
						<aside class="notes">
							"En nu wil ik het zien werken". Snap ik, daarom ga ik nu een demo geven van Excalibur, en de extra functionaliteit
							die er nu in zit. 

							We hebben hier de Excalibur UI: je hebt een zoekbalk, je kan zowel met tekst als met een afbeelding zoeken.
							Laten we beginnen met tekst. De demo dataset die we hier in hebben geladen bevat elf honderd plaatjes die 
							te maken hebben met iets van luxe goederen, luxe levensstijl, etc.

							Dus stel voor dat ik wil weten of er dure flessen aanwezig zijn in de dataset. Ik kan dan een zoekquery gaan intypen.
							...demo van expensive bottle...
							We zien hier zowel flessen parfum als flessen met alcohol staan. Stel dat ik nu alleen de flessen met alcohol wil zien,
							en niet flessen parfum. Wat je nu kan doen is dat je je resultaten gaat verfijnen, of finetunen zoals we het genoemd hebben.
							Dit finetunen is vooral handig als je exploratief bezig bent en niet direct weet wat er in de data zit, en gaandeweg nieuwe
							dingen ontdekt in je zoektocht binnen de dataset. Ook is dit heel handig voor als je hele specifieke subsets van de data
							wil gaan isoleren en bekijken, waar het model misschien geen kennis over heeft. Een goed voorbeeld hiervan is: stel je 
							typt in "a photo of an airport", omdat je wil weten of de verdachte foto's heeft uit een vliegveld. Als resultaten krijg
							je vervolgens 200 foto's van allerlei vliegvelden te zien, maar je spot er ook twee uit Schiphol. Nu ben je extra geinteresseerd:
							heeft mijn verdachte nog verder foto's uit Schiphol? Het model weet waarschijnlijk niet (goed) wat Schiphol is, omdat het
							te specifiek is, maar door middel van finetunen kan je nu de Schiphol plaatjes als relevant aanklikken en de andere vliegvelden 
							als niet relevant, en krijg je hopelijk meer foto's van Schiphol te zien! Hoe het finetuning proces precies werkt ga ik 
							in deze sessie niet vertellen, maar het maakt gebruik van een ander machine learning model wat live leert van je handelingen.

							Ook kan je natuurlijk met een afbeelding zoeken.
							...image search demo...
						</aside>
					</section>
					<section>
						<p style="font-size: 40px; color: whitesmoke;">Excalibur, een overzicht</p>
						<ul>
							<li class="text-color-2 fragment fade-up" style="font-size: 30px;">Realiteit: meer data in een zaak dan een rechercheur effectief kan analyseren</li>
							<li class="text-color-2 fragment fade-up" style="font-size: 30px;">Huidige tools (bijvoorbeeld Cellebrite) hebben limitaties op het gebied van zoeken in foto's</li>
							<ul>
								<li class="text-color-2 fragment fade-up" style="font-size: 25px;">Gelimiteerd aan vooraf gedefinieerde categorie√´n om in te zoeken</li>
							</ul>
							<li class="text-color-2 fragment fade-up" style="font-size: 30px;">Zoeken met zowel natuurlijke taal als met afbeeldingen</li>
							<li class="text-color-2 fragment fade-up" style="font-size: 30px;">Mogelijkheid om de zoekresultaten te verfijnen met interactive learning</li>
						</ul>
						<aside class="notes">
							Nu dat we veel gezien en geprobeerd hebben, even een samenvatting van de afgelopen slide of 25.
							1) De realiteit is dat er anno 2022 enorm veel data in een zaak zit; vaak veel meer dan een rechercheur effectief kan analyseren
							2) De huidige tools om met afbeeldingen te werken, zoals Cellebrite, hebben limitaties...
							3)...bijvoorbeeld dat er alleen op vooraf gedefineerde categorieen gezocht kan worden
							4) Excalibur maakt het mogelijk om om met zowel natuurlijke taal als met afbeeldingen te zoeken
							5) Er is binnen Excalibur de mogelijkheid om de zoekresultaten te verfijnen met interactive learning, waar je zelf als gebruiker bepaalt
							wat wel en niet relevant is.
						</aside>
					</section>
				</section>
				<section data-background-color="#154c79">
					<p style="font-size: 40px; color: whitesmoke;">Wat zijn de volgende stappen?</p>
					<!-- TODO met Niels -->
					<ul>
						<li class="text-color-white fragment fade-up" style="font-size: 30px;">Excalibur is een vrij zware applicatie --> niet makkelijk om breed te deployen</li>
						<li class="text-color-white fragment fade-up" style="font-size: 30px;">Het plan: Excalibur beschikbaar maken op standalone machines in verschillende regios</li>
						<li class="text-color-white fragment fade-up" style="font-size: 30px;">Jullie input :)</li>
					</ul>
					<aside class="notes">
						<!-- TODO -->
					</aside>
				</section>
				<section data-background-color="#154c79" data-auto-animate>
					<p style="font-size: 70px; color: whitesmoke; display: inline;">Dank voor jullie</p>
					<p style="font-size: 70px; color: whitesmoke; display: inline;">tijd</p>
					<aside class="notes">
						Dan ziet de presentatie bij deze erop, en wil ik jullie als eerst bedanken voor jullie tijd...
					</aside>
				</section>
				<section data-background-color="#154c79" data-auto-animate>
					<p style="font-size: 70px; color: whitesmoke; display: inline;">tijd</p>
					<p style="font-size: 70px; color: whitesmoke; display: inline;">voor vragen!</p>
					<aside class="notes">
						...en is het tijd voor vragen!
					</aside>
				</section>
				<section data-background-color="#154c79" data-auto-animate>
					<p style="font-size: 70px; color: whitesmoke; display: inline;">Zelf aan de gang met Excalibur</p>
					<aside class="notes">
						<!-- TODO -->
					</aside>
				</section>
			</div>
		</div>

		<script src="dist/reveal.js"></script>
		<script src="plugin/notes/notes.js"></script>
		<script src="plugin/markdown/markdown.js"></script>
		<script src="plugin/highlight/highlight.js"></script>
		<script>
			// More info about initialization & config:
			// - https://revealjs.com/initialization/
			// - https://revealjs.com/config/
			Reveal.initialize({
				hash: true,

				// Learn about plugins: https://revealjs.com/plugins/
				plugins: [ RevealMarkdown, RevealHighlight, RevealNotes ]
			});
		</script>
	</body>
</html>
